{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d173062f",
   "metadata": {},
   "source": [
    "### GXB Hypter-parameter Tuning\n",
    "\n",
    "1. All variables, no resampling\n",
    "\n",
    "2. All variables, resampling\n",
    "\n",
    "3. 12 variables, no resampling\n",
    "\n",
    "4. 12 variables, resampling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76ac296b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost\n",
    "from xgboost import XGBRegressor\n",
    "# from sklearn.metrics import accuracy_score, confusion_matrix, auc\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d93c0dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preprocessed = pd.read_csv('data/train_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "598ce1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(563547, 59) (277568, 59) (563547,) (277568,)\n"
     ]
    }
   ],
   "source": [
    "# Randomly, split the data into test/training/validation sets\n",
    "x = train_preprocessed.drop(['prop_booking_bool'], axis=1)\n",
    "y = train_preprocessed['prop_booking_bool']\n",
    "\n",
    "x_train, x_test, y_train, y_test  = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65691190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data inputs (IVs): (563547, 59)\n",
      "Shape of testing data inputs (IVs) : (277568, 59)\n"
     ]
    }
   ],
   "source": [
    " # shape of the dataset \n",
    "print('Shape of training data inputs (IVs):', x_train.shape)\n",
    "print('Shape of testing data inputs (IVs) :', x_test.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82af76fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed: 15.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None, colsample_bytree=0.8,\n",
       "                                    gamma=0.1, gpu_id=None,\n",
       "                                    importance_type='gain',\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=0.1, max_delta_step=None,\n",
       "                                    max_depth=None, min_child_weight=None,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n_estimators=100, n_jobs=None,\n",
       "                                    num_parallel_tree=None,\n",
       "                                    objective='rank:ndcg', random_state=None,\n",
       "                                    reg_alpha=1, reg_lambda=1,\n",
       "                                    scale_pos_weight=None, seed=123,\n",
       "                                    subsample=None, tree_method=None,\n",
       "                                    validate_parameters=None, verbosity=None),\n",
       "             param_grid={'max_depth': [2, 4, 6, 8],\n",
       "                         'min_child_weight': [1, 3, 5, 7]},\n",
       "             scoring='neg_mean_squared_error', verbose=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First try, parameter tuning for XGB\n",
    "# tune for MAX_DEPTH & MIN_CHILD_WEIGHT\n",
    "objective = \"rank:ndcg\"\n",
    "seed = 123\n",
    "n_estimators = 100\n",
    "learning_rate = 0.1\n",
    "gamma = 0.1\n",
    "subsample = 0.8\n",
    "colsample_bytree = 0.8\n",
    "reg_alpha = 1\n",
    "reg_lambda = 1\n",
    "\n",
    "args = {}\n",
    "args['objective'] = objective\n",
    "args['seed'] = seed\n",
    "args['n_estimators'] = n_estimators\n",
    "args['learning_rate'] = learning_rate\n",
    "args['gamma'] = gamma\n",
    "args['colsample_bytree'] = colsample_bytree\n",
    "args['reg_alpha'] = reg_alpha\n",
    "args['reg_lambda'] = reg_lambda\n",
    "\n",
    "scores = []\n",
    "\n",
    "cv_params = {'max_depth': [2,4,6,8],\n",
    "             'min_child_weight': [1,3,5,7]\n",
    "            }\n",
    "\n",
    "gbm = GridSearchCV(xgboost.XGBRegressor(**args),\n",
    "                    param_grid = cv_params,\n",
    "                    scoring = \"neg_mean_squared_error\",\n",
    "                    cv = 5,\n",
    "                    verbose = True\n",
    ")\n",
    "\n",
    "gbm.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9da58132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None, colsample_bytree=0.8,\n",
       "                                    gamma=0.1, gpu_id=None,\n",
       "                                    importance_type='gain',\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=0.1, max_delta_step=None,\n",
       "                                    max_depth=None, min_child_weight=None,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n_estimators=100, n_jobs=None,\n",
       "                                    num_parallel_tree=None, random_state=None,\n",
       "                                    reg_alpha=1, reg_lambda=1,\n",
       "                                    scale_pos_weight=None, seed=123,\n",
       "                                    subsample=None, tree_method=None,\n",
       "                                    validate_parameters=None, verbosity=None),\n",
       "             param_grid={'max_depth': [2, 4, 6, 8],\n",
       "                         'min_child_weight': [1, 3, 5, 7]},\n",
       "             scoring='neg_mean_squared_error', verbose=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GridSearchCV(cv=5,\n",
    "             estimator=XGBRegressor(base_score=None, booster=None,\n",
    "                                    colsample_bylevel=None,\n",
    "                                    colsample_bynode=None, colsample_bytree=0.8,\n",
    "                                    gamma=0.1, gpu_id=None,\n",
    "                                    importance_type='gain',\n",
    "                                    interaction_constraints=None,\n",
    "                                    learning_rate=0.1, max_delta_step=None,\n",
    "                                    max_depth=None, min_child_weight=None,\n",
    "                                    missing=np.nan, monotone_constraints=None,\n",
    "                                    n_estimators=100, n_jobs=None,\n",
    "                                    num_parallel_tree=None, random_state=None,\n",
    "                                    reg_alpha=1, reg_lambda=1,\n",
    "                                    scale_pos_weight=None, seed=123,\n",
    "                                    subsample=None, tree_method=None,\n",
    "                                    validate_parameters=None, verbosity=None),\n",
    "             param_grid={'max_depth': [2, 4, 6, 8],\n",
    "                         'min_child_weight': [1, 3, 5, 7]},\n",
    "             scoring='neg_mean_squared_error', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a41b6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters {'max_depth': 2, 'min_child_weight': 1}\n",
      "Best score -0.25\n"
     ]
    }
   ],
   "source": [
    "# print(gbm.cv_results_)\n",
    "print(\"Best parameters %s\" %gbm.best_params_)\n",
    "print(\"Best score %s\" %gbm.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb4cc173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed: 18.8min finished\n",
      "/Users/tabithajohnston/opt/anaconda3/envs/expedia_kaggle/lib/python3.6/site-packages/sklearn/model_selection/_search.py:849: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None, colsample_bytree=0.8,\n",
       "                                    gamma=0.1, gpu_id=None,\n",
       "                                    importance_type='gain',\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=0.1, max_delta_step=None,\n",
       "                                    max_depth=2, min_child_weight=1,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n_estimators=100, n_jobs=None,\n",
       "                                    num_parallel_tree=None,\n",
       "                                    objective='rank:ndcg', random_state=None,\n",
       "                                    reg_alpha=1, reg_lambda=1,\n",
       "                                    scale_pos_weight=None, seed=123,\n",
       "                                    subsample=None, tree_method=None,\n",
       "                                    validate_parameters=None, verbosity=None),\n",
       "             iid=False,\n",
       "             param_grid={'max_depth': [1, 2, 3],\n",
       "                         'min_child_weight': [0, 0.5, 1, 1.5, 2]},\n",
       "             scoring='neg_mean_squared_error', verbose=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Refine MAX_DEPTH & MIN_CHILD_WEIGHT with smaller grid of values, based on best performer from previous step\n",
    "# MIN_CHILD_WEIGHT = min no. samples (if all samples have a weight 1) required to create a new node in the tree.\n",
    "max_depth = gbm.best_params_['max_depth']\n",
    "min_child_weight = gbm.best_params_['min_child_weight']\n",
    "args['max_depth'] = max_depth\n",
    "args['min_child_weight'] = min_child_weight\n",
    "scores.append(gbm.best_score_)\n",
    "\n",
    "cv_params = {'max_depth': [max_depth-1, max_depth, max_depth+1], \n",
    "             'min_child_weight': [min_child_weight-1, min_child_weight-0.5, min_child_weight, min_child_weight+0.5, min_child_weight+1]\n",
    "            }\n",
    "\n",
    "gbm = GridSearchCV(xgboost.XGBRegressor(**args),\n",
    "                    param_grid = cv_params,\n",
    "                    iid = False,\n",
    "                    scoring = \"neg_mean_squared_error\",\n",
    "                    cv = 5,\n",
    "                    verbose = True\n",
    ")\n",
    "\n",
    "gbm.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3e0d719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None, colsample_bytree=0.8,\n",
       "                                    gamma=0.1, gpu_id=None,\n",
       "                                    importance_type='gain',\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=0.1, max_delta_step=None,\n",
       "                                    max_depth=8, min_child_weight=3,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n_estimators=100, n_jobs=None,\n",
       "                                    num_parallel_tree=None, random_state=None,\n",
       "                                    reg_alpha=1, reg_lambda=1,\n",
       "                                    scale_pos_weight=None, seed=123,\n",
       "                                    subsample=None, tree_method=None,\n",
       "                                    validate_parameters=None, verbosity=None),\n",
       "             iid=False,\n",
       "             param_grid={'max_depth': [7, 8, 9],\n",
       "                         'min_child_weight': [2, 2.5, 3, 3.5, 4]},\n",
       "             scoring='neg_mean_squared_error', verbose=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " GridSearchCV(cv=5,\n",
    "             estimator=XGBRegressor(base_score=None, booster=None,\n",
    "                                    colsample_bylevel=None,\n",
    "                                    colsample_bynode=None, colsample_bytree=0.8,\n",
    "                                    gamma=0.1, gpu_id=None,\n",
    "                                    importance_type='gain',\n",
    "                                    interaction_constraints=None,\n",
    "                                    learning_rate=0.1, max_delta_step=None,\n",
    "                                    max_depth=8, min_child_weight=3,\n",
    "                                    missing=np.nan, monotone_constraints=None,\n",
    "                                    n_estimators=100, n_jobs=None,\n",
    "                                    num_parallel_tree=None, random_state=None,\n",
    "                                    reg_alpha=1, reg_lambda=1,\n",
    "                                    scale_pos_weight=None, seed=123,\n",
    "                                    subsample=None, tree_method=None,\n",
    "                                    validate_parameters=None, verbosity=None),\n",
    "             iid=False,\n",
    "             param_grid={'max_depth': [7, 8, 9],\n",
    "                         'min_child_weight': [2, 2.5, 3, 3.5, 4]},\n",
    "             scoring='neg_mean_squared_error', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a2ebc38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  4.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None, colsample_bytree=0.8,\n",
       "                                    gamma=0.1, gpu_id=None,\n",
       "                                    importance_type='gain',\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=0.1, max_delta_step=None,\n",
       "                                    max_depth=1, min_child_weight=0,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n_estimators=100, n_jobs=None,\n",
       "                                    num_parallel_tree=None,\n",
       "                                    objective='rank:ndcg', random_state=None,\n",
       "                                    reg_alpha=1, reg_lambda=1,\n",
       "                                    scale_pos_weight=None, seed=123,\n",
       "                                    subsample=None, tree_method=None,\n",
       "                                    validate_parameters=None, verbosity=None),\n",
       "             param_grid={'gamma': [0.0, 0.2, 0.4, 0.6, 0.8]},\n",
       "             scoring='neg_mean_squared_error', verbose=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set MAX_DEPTH & MIN_CHILD_WEIGHT\n",
    "# tune for GAMMA (how fiercely the tree gets pruned. balance against lambda)\n",
    "max_depth = gbm.best_params_['max_depth']\n",
    "min_child_weight = gbm.best_params_['min_child_weight'] # overwritten to be conservative & avoid overfitting\n",
    "args['max_depth'] = max_depth\n",
    "args['min_child_weight'] = min_child_weight\n",
    "scores.append(gbm.best_score_)\n",
    "\n",
    "cv_params = {'gamma': [i/10.0 for i in range(0, 10, 2)]}\n",
    "\n",
    "gbm = GridSearchCV(xgboost.XGBRegressor(**args),\n",
    "                    param_grid = cv_params,\n",
    "                    scoring = \"neg_mean_squared_error\",\n",
    "                    cv = 5,\n",
    "                    verbose = True\n",
    ")\n",
    "\n",
    "gbm.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9c3cd3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None, colsample_bytree=0.8,\n",
       "                                    gamma=0.1, gpu_id=None,\n",
       "                                    importance_type='gain',\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=0.1, max_delta_step=None,\n",
       "                                    max_depth=7, min_child_weight=2.5,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n_estimators=100, n_jobs=None,\n",
       "                                    num_parallel_tree=None, random_state=None,\n",
       "                                    reg_alpha=1, reg_lambda=1,\n",
       "                                    scale_pos_weight=None, seed=123,\n",
       "                                    subsample=None, tree_method=None,\n",
       "                                    validate_parameters=None, verbosity=None),\n",
       "             param_grid={'gamma': [0.0, 0.2, 0.4, 0.6, 0.8]},\n",
       "             scoring='neg_mean_squared_error', verbose=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " GridSearchCV(cv=5,\n",
    "             estimator=XGBRegressor(base_score=None, booster=None,\n",
    "                                    colsample_bylevel=None,\n",
    "                                    colsample_bynode=None, colsample_bytree=0.8,\n",
    "                                    gamma=0.1, gpu_id=None,\n",
    "                                    importance_type='gain',\n",
    "                                    interaction_constraints=None,\n",
    "                                    learning_rate=0.1, max_delta_step=None,\n",
    "                                    max_depth=7, min_child_weight=2.5,\n",
    "                                    missing=np.nan, monotone_constraints=None,\n",
    "                                    n_estimators=100, n_jobs=None,\n",
    "                                    num_parallel_tree=None, random_state=None,\n",
    "                                    reg_alpha=1, reg_lambda=1,\n",
    "                                    scale_pos_weight=None, seed=123,\n",
    "                                    subsample=None, tree_method=None,\n",
    "                                    validate_parameters=None, verbosity=None),\n",
    "             param_grid={'gamma': [0.0, 0.2, 0.4, 0.6, 0.8]},\n",
    "             scoring='neg_mean_squared_error', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9821ea72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 125 out of 125 | elapsed: 26.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None, colsample_bytree=0.8,\n",
       "                                    gamma=0.0, gpu_id=None,\n",
       "                                    importance_type='gain',\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=0.1, max_delta_step=None,\n",
       "                                    max_depth=1, min_child_weight=0,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n_estimators=100, n_jobs=None,\n",
       "                                    num_parallel_tree=None,\n",
       "                                    objective='rank:ndcg', random_state=None,\n",
       "                                    reg_alpha=1, reg_lambda=1,\n",
       "                                    scale_pos_weight=None, seed=123,\n",
       "                                    subsample=None, tree_method=None,\n",
       "                                    validate_parameters=None, verbosity=None),\n",
       "             param_grid={'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
       "                         'subsample': [0.6, 0.7, 0.8, 0.9, 1.0]},\n",
       "             scoring='neg_mean_squared_error', verbose=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the GAMMA parameter and tune the SUBSAMPLE & COLSAMPLE_BYTREE parameters next\n",
    "# (these control the sampling of the dataset that is done at each boosting round) SUBSAMPLE = fraction of rows. COLSAMPLE_BYTREE = fraction of cols\n",
    "gamma = gbm.best_params_['gamma']\n",
    "args['gamma'] = gamma\n",
    "scores.append(gbm.best_score_)\n",
    "\n",
    "cv_params = {'subsample': [i/10.0 for i in range(6,11)],\n",
    "             'colsample_bytree': [i/10.0 for i in range(6,11)]\n",
    "            }\n",
    "\n",
    "gbm = GridSearchCV(xgboost.XGBRegressor(**args),\n",
    "                    param_grid = cv_params,\n",
    "                    scoring = \"neg_mean_squared_error\",\n",
    "                    cv = 5,\n",
    "                    verbose = True\n",
    ")\n",
    "\n",
    "gbm.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2141a40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None, colsample_bytree=0.8,\n",
       "                                    gamma=0.0, gpu_id=None,\n",
       "                                    importance_type='gain',\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=0.1, max_delta_step=None,\n",
       "                                    max_depth=7, min_child_weight=2.5,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n_estimators=100, n_jobs=None,\n",
       "                                    num_parallel_tree=None, random_state=None,\n",
       "                                    reg_alpha=1, reg_lambda=1,\n",
       "                                    scale_pos_weight=None, seed=123,\n",
       "                                    subsample=None, tree_method=None,\n",
       "                                    validate_parameters=None, verbosity=None),\n",
       "             param_grid={'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
       "                         'subsample': [0.6, 0.7, 0.8, 0.9, 1.0]},\n",
       "             scoring='neg_mean_squared_error', verbose=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GridSearchCV(cv=5,\n",
    "             estimator=XGBRegressor(base_score=None, booster=None,\n",
    "                                    colsample_bylevel=None,\n",
    "                                    colsample_bynode=None, colsample_bytree=0.8,\n",
    "                                    gamma=0.0, gpu_id=None,\n",
    "                                    importance_type='gain',\n",
    "                                    interaction_constraints=None,\n",
    "                                    learning_rate=0.1, max_delta_step=None,\n",
    "                                    max_depth=7, min_child_weight=2.5,\n",
    "                                    missing=np.nan, monotone_constraints=None,\n",
    "                                    n_estimators=100, n_jobs=None,\n",
    "                                    num_parallel_tree=None, random_state=None,\n",
    "                                    reg_alpha=1, reg_lambda=1,\n",
    "                                    scale_pos_weight=None, seed=123,\n",
    "                                    subsample=None, tree_method=None,\n",
    "                                    validate_parameters=None, verbosity=None),\n",
    "             param_grid={'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                         'subsample': [0.6, 0.7, 0.8, 0.9, 1.0]},\n",
    "             scoring='neg_mean_squared_error', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bf7a13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed: 16.5min finished\n",
      "/Users/tabithajohnston/opt/anaconda3/envs/expedia_kaggle/lib/python3.6/site-packages/sklearn/model_selection/_search.py:849: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None, colsample_bytree=0.6,\n",
       "                                    gamma=0.0, gpu_id=None,\n",
       "                                    importance_type='gain',\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=0.1, max_delta_step=None,\n",
       "                                    max_depth=1, min_child_weight=0,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n_estimators=100, n_jobs=None,\n",
       "                                    num_parallel_tree=None,\n",
       "                                    objective='rank:ndcg', random_state=None,\n",
       "                                    reg_alpha=1, reg_lambda=1,\n",
       "                                    scale_pos_weight=None, seed=123,\n",
       "                                    subsample=0.6, tree_method=None,\n",
       "                                    validate_parameters=None, verbosity=None),\n",
       "             iid=False,\n",
       "             param_grid={'colsample_bytree': [0.5, 0.55, 0.6, 0.65],\n",
       "                         'subsample': [0.5, 0.55, 0.6, 0.65]},\n",
       "             scoring='neg_mean_squared_error', verbose=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retune SUBSAMPLE & COLSAMPLE_BYTREE with a smaller grid of values based on best values above\n",
    "subsample = gbm.best_params_['subsample']\n",
    "colsample_bytree = gbm.best_params_['colsample_bytree']\n",
    "args['subsample'] = subsample\n",
    "args['colsample_bytree'] = colsample_bytree\n",
    "scores.append(gbm.best_score_)\n",
    "\n",
    "cv_params = {'subsample': [i/100.0 for i in range(int((subsample-0.1)*100.0), min(int((subsample+0.1)*100),105) , 5)],\n",
    "             'colsample_bytree': [i/100.0 for i in range(int((colsample_bytree-0.1)*100.0), min(int((subsample+0.1)*100),105), 5)]\n",
    "            }\n",
    "\n",
    "gbm = GridSearchCV(xgboost.XGBRegressor(**args),\n",
    "                   \n",
    "                    param_grid = cv_params,\n",
    "                    iid = False,\n",
    "                    scoring = \"neg_mean_squared_error\",\n",
    "                    cv = 5,\n",
    "                    verbose = True\n",
    ")\n",
    "\n",
    "gbm.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f2ed2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None, colsample_bytree=0.6,\n",
       "                                    gamma=0.0, gpu_id=None,\n",
       "                                    importance_type='gain',\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=0.1, max_delta_step=None,\n",
       "                                    max_depth=7, min_child_weight=2.5,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n_estimators=100, n_jobs=None,\n",
       "                                    num_parallel_tree=None, random_state=None,\n",
       "                                    reg_alpha=1, reg_lambda=1,\n",
       "                                    scale_pos_weight=None, seed=123,\n",
       "                                    subsample=0.8, tree_method=None,\n",
       "                                    validate_parameters=None, verbosity=None),\n",
       "             iid=False,\n",
       "             param_grid={'colsample_bytree': [0.5, 0.55, 0.6, 0.65, 0.7, 0.75,\n",
       "                                              0.8, 0.85],\n",
       "                         'subsample': [0.7, 0.75, 0.8, 0.85]},\n",
       "             scoring='neg_mean_squared_error', verbose=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GridSearchCV(cv=5,\n",
    "             estimator=XGBRegressor(base_score=None, booster=None,\n",
    "                                    colsample_bylevel=None,\n",
    "                                    colsample_bynode=None, colsample_bytree=0.6,\n",
    "                                    gamma=0.0, gpu_id=None,\n",
    "                                    importance_type='gain',\n",
    "                                    interaction_constraints=None,\n",
    "                                    learning_rate=0.1, max_delta_step=None,\n",
    "                                    max_depth=7, min_child_weight=2.5,\n",
    "                                    missing=np.nan, monotone_constraints=None,\n",
    "                                    n_estimators=100, n_jobs=None,\n",
    "                                    num_parallel_tree=None, random_state=None,\n",
    "                                    reg_alpha=1, reg_lambda=1,\n",
    "                                    scale_pos_weight=None, seed=123,\n",
    "                                    subsample=0.8, tree_method=None,\n",
    "                                    validate_parameters=None, verbosity=None),\n",
    "             iid=False,\n",
    "             param_grid={'colsample_bytree': [0.5, 0.55, 0.6, 0.65, 0.7, 0.75,\n",
    "                                              0.8, 0.85],\n",
    "                         'subsample': [0.7, 0.75, 0.8, 0.85]},\n",
    "             scoring='neg_mean_squared_error', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcb14d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 125 out of 125 | elapsed: 34.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None, colsample_bytree=0.5,\n",
       "                                    gamma=0.0, gpu_id=None,\n",
       "                                    importance_type='gain',\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=0.1, max_delta_step=None,\n",
       "                                    max_depth=1, min_child_weight=0,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n_estimators=100, n_jobs=None,\n",
       "                                    num_parallel_tree=None,\n",
       "                                    objective='rank:ndcg', random_state=None,\n",
       "                                    reg_alpha=1, reg_lambda=1,\n",
       "                                    scale_pos_weight=None, seed=123,\n",
       "                                    subsample=0.5, tree_method=None,\n",
       "                                    validate_parameters=None, verbosity=None),\n",
       "             param_grid={'reg_alpha': [1e-05, 0.01, 0.1, 1, 100],\n",
       "                         'reg_lambda': [1e-05, 0.01, 0.1, 1, 100]},\n",
       "             scoring='neg_mean_squared_error', verbose=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the SUBSAMPLE & COLSAMPLE_BYTREE parameters \n",
    "# tune REG_ALPHA & REG_LAMBDA (regularisation params)\n",
    "colsample_bytree = gbm.best_params_['colsample_bytree']\n",
    "subsample = gbm.best_params_['subsample']\n",
    "args['colsample_bytree'] = colsample_bytree\n",
    "args['subsample'] = subsample\n",
    "scores.append(gbm.best_score_)\n",
    "\n",
    "cv_params = {'reg_alpha': [1e-5, 1e-2, 0.1, 1, 100], \n",
    "             'reg_lambda': [1e-5, 1e-2, 0.1, 1, 100]\n",
    "            }\n",
    "\n",
    "gbm = GridSearchCV(xgboost.XGBRegressor(**args),\n",
    "                    param_grid = cv_params,\n",
    "                    scoring = \"neg_mean_squared_error\",\n",
    "                    cv = 5,\n",
    "                    verbose = True\n",
    ")\n",
    "\n",
    "gbm.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c03f333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None, colsample_bytree=0.6,\n",
       "                                    gamma=0.0, gpu_id=None,\n",
       "                                    importance_type='gain',\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=0.1, max_delta_step=None,\n",
       "                                    max_depth=7, min_child_weight=2.5,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n_estimators=100, n_jobs=None,\n",
       "                                    num_parallel_tree=None, random_state=None,\n",
       "                                    reg_alpha=1, reg_lambda=1,\n",
       "                                    scale_pos_weight=None, seed=123,\n",
       "                                    subsample=0.8, tree_method=None,\n",
       "                                    validate_parameters=None, verbosity=None),\n",
       "             param_grid={'reg_alpha': [1e-05, 0.01, 0.1, 1, 100],\n",
       "                         'reg_lambda': [1e-05, 0.01, 0.1, 1, 100]},\n",
       "             scoring='neg_mean_squared_error', verbose=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " GridSearchCV(cv=5,\n",
    "             estimator=XGBRegressor(base_score=None, booster=None,\n",
    "                                    colsample_bylevel=None,\n",
    "                                    colsample_bynode=None, colsample_bytree=0.6,\n",
    "                                    gamma=0.0, gpu_id=None,\n",
    "                                    importance_type='gain',\n",
    "                                    interaction_constraints=None,\n",
    "                                    learning_rate=0.1, max_delta_step=None,\n",
    "                                    max_depth=7, min_child_weight=2.5,\n",
    "                                    missing=np.nan, monotone_constraints=None,\n",
    "                                    n_estimators=100, n_jobs=None,\n",
    "                                    num_parallel_tree=None, random_state=None,\n",
    "                                    reg_alpha=1, reg_lambda=1,\n",
    "                                    scale_pos_weight=None, seed=123,\n",
    "                                    subsample=0.8, tree_method=None,\n",
    "                                    validate_parameters=None, verbosity=None),\n",
    "             param_grid={'reg_alpha': [1e-05, 0.01, 0.1, 1, 100],\n",
    "                         'reg_lambda': [1e-05, 0.01, 0.1, 1, 100]},\n",
    "             scoring='neg_mean_squared_error', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "098dcbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 125 out of 125 | elapsed: 26.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None, colsample_bytree=0.5,\n",
       "                                    gamma=0.0, gpu_id=None,\n",
       "                                    importance_type='gain',\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=0.1, max_delta_step=None,\n",
       "                                    max_depth=1, min_child_weight=0,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n_estimators=100, n_jobs=None,\n",
       "                                    num_parallel_tree=None,\n",
       "                                    objective='rank:ndcg', random_state=None,\n",
       "                                    reg_alpha=0.01, reg_lambda=1,\n",
       "                                    scale_pos_weight=None, seed=123,\n",
       "                                    subsample=0.5, tree_method=None,\n",
       "                                    validate_parameters=None, verbosity=None),\n",
       "             param_grid={'reg_alpha': [0.2, 0.5, 1, 2, 5],\n",
       "                         'reg_lambda': [0.002, 0.005, 0.01, 0.02, 0.05]},\n",
       "             scoring='neg_mean_squared_error', verbose=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retune REG_ALPHA & REG_LAMBDA with a smaller grid of values based on best values above\n",
    "reg_alpha = gbm.best_params_['reg_alpha']\n",
    "reg_lambda = gbm.best_params_['reg_lambda']\n",
    "args['reg_alpha'] = reg_alpha\n",
    "args['reg_lambda'] = reg_lambda\n",
    "scores.append(gbm.best_score_)\n",
    "\n",
    "cv_params = {'reg_lambda': [reg_alpha*0.2, reg_alpha*0.5, reg_alpha, reg_alpha*2, reg_alpha*5], \n",
    "             'reg_alpha': [reg_lambda*0.2, reg_lambda*0.5, reg_lambda, reg_lambda*2, reg_lambda*5]\n",
    "            }\n",
    "\n",
    "gbm = GridSearchCV(xgboost.XGBRegressor(**args),\n",
    "                    param_grid = cv_params,\n",
    "                    scoring = \"neg_mean_squared_error\",\n",
    "                    cv = 5,\n",
    "                    verbose = True\n",
    ")\n",
    "\n",
    "gbm.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9eba92d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None, colsample_bytree=0.6,\n",
       "                                    gamma=0.0, gpu_id=None,\n",
       "                                    importance_type='gain',\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=0.1, max_delta_step=None,\n",
       "                                    max_depth=7, min_child_weight=2.5,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n_estimators=100, n_jobs=None,\n",
       "                                    num_parallel_tree=None, random_state=None,\n",
       "                                    reg_alpha=1, reg_lambda=1,\n",
       "                                    scale_pos_weight=None, seed=123,\n",
       "                                    subsample=0.8, tree_method=None,\n",
       "                                    validate_parameters=None, verbosity=None),\n",
       "             param_grid={'reg_alpha': [0.2, 0.5, 1, 2, 5],\n",
       "                         'reg_lambda': [0.2, 0.5, 1, 2, 5]},\n",
       "             scoring='neg_mean_squared_error', verbose=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GridSearchCV(cv=5,\n",
    "             estimator=XGBRegressor(base_score=None, booster=None,\n",
    "                                    colsample_bylevel=None,\n",
    "                                    colsample_bynode=None, colsample_bytree=0.6,\n",
    "                                    gamma=0.0, gpu_id=None,\n",
    "                                    importance_type='gain',\n",
    "                                    interaction_constraints=None,\n",
    "                                    learning_rate=0.1, max_delta_step=None,\n",
    "                                    max_depth=7, min_child_weight=2.5,\n",
    "                                    missing=np.nan, monotone_constraints=None,\n",
    "                                    n_estimators=100, n_jobs=None,\n",
    "                                    num_parallel_tree=None, random_state=None,\n",
    "                                    reg_alpha=1, reg_lambda=1,\n",
    "                                    scale_pos_weight=None, seed=123,\n",
    "                                    subsample=0.8, tree_method=None,\n",
    "                                    validate_parameters=None, verbosity=None),\n",
    "             param_grid={'reg_alpha': [0.2, 0.5, 1, 2, 5],\n",
    "                         'reg_lambda': [0.2, 0.5, 1, 2, 5]},\n",
    "             scoring='neg_mean_squared_error', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7410f549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters {'reg_alpha': 0.2, 'reg_lambda': 0.002}\n",
      "Best score -0.25\n"
     ]
    }
   ],
   "source": [
    "# print(gbm.cv_results_)\n",
    "print(\"Best parameters %s\" %gbm.best_params_)\n",
    "print(\"Best score %s\" %gbm.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27ca4e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the regularisationparameters: REG_ALPHA & REG_LAMBDA \n",
    "# (then increase trees & reduce learning rate)\n",
    "reg_alpha = gbm.best_params_['reg_alpha']\n",
    "reg_lambda = gbm.best_params_['reg_lambda']\n",
    "args['reg_alpha'] = reg_alpha\n",
    "args['reg_lambda'] = reg_lambda\n",
    "scores.append(gbm.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "663d0a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'rank:ndcg', 'seed': 123, 'n_estimators': 100, 'learning_rate': 0.1, 'gamma': 0.0, 'colsample_bytree': 0.5, 'reg_alpha': 0.2, 'reg_lambda': 0.002, 'max_depth': 3, 'min_child_weight': 0, 'subsample': 0.5, 'eta': 0.05, 'eval_metric': 'rmse'}\n",
      "[-0.25, -0.25, -0.25, -0.25, -0.25, -0.09883558710896737, -0.25]\n"
     ]
    }
   ],
   "source": [
    "print(args)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a2bd930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create XGBoost's DMatrix - for finding the best tree from CV & for final model\n",
    "trainDMat = xgboost.DMatrix(data = x_train, label = y_train)\n",
    "testDMat = xgboost.DMatrix(data = x_test, label = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7633c0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:46:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:46:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:46:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:46:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:46:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-logloss:0.69302+0.00000\ttrain-rmse:0.50000+0.00000\ttest-logloss:0.69326+0.00000\ttest-rmse:0.50000+0.00000\n",
      "[1]\ttrain-logloss:0.69302+0.00000\ttrain-rmse:0.50000+0.00000\ttest-logloss:0.69326+0.00000\ttest-rmse:0.50000+0.00000\n",
      "[2]\ttrain-logloss:0.69302+0.00000\ttrain-rmse:0.50000+0.00000\ttest-logloss:0.69326+0.00000\ttest-rmse:0.50000+0.00000\n",
      "[3]\ttrain-logloss:0.69302+0.00000\ttrain-rmse:0.50000+0.00000\ttest-logloss:0.69326+0.00000\ttest-rmse:0.50000+0.00000\n",
      "[4]\ttrain-logloss:0.69302+0.00000\ttrain-rmse:0.50000+0.00000\ttest-logloss:0.69326+0.00000\ttest-rmse:0.50000+0.00000\n",
      "[5]\ttrain-logloss:0.69302+0.00000\ttrain-rmse:0.50000+0.00000\ttest-logloss:0.69326+0.00000\ttest-rmse:0.50000+0.00000\n",
      "[6]\ttrain-logloss:0.69302+0.00000\ttrain-rmse:0.50000+0.00000\ttest-logloss:0.69326+0.00000\ttest-rmse:0.50000+0.00000\n",
      "[7]\ttrain-logloss:0.69302+0.00000\ttrain-rmse:0.50000+0.00000\ttest-logloss:0.69326+0.00000\ttest-rmse:0.50000+0.00000\n",
      "[8]\ttrain-logloss:0.69302+0.00000\ttrain-rmse:0.50000+0.00000\ttest-logloss:0.69326+0.00000\ttest-rmse:0.50000+0.00000\n",
      "[9]\ttrain-logloss:0.69302+0.00000\ttrain-rmse:0.50000+0.00000\ttest-logloss:0.69326+0.00000\ttest-rmse:0.50000+0.00000\n",
      "[10]\ttrain-logloss:0.69302+0.00000\ttrain-rmse:0.50000+0.00000\ttest-logloss:0.69326+0.00000\ttest-rmse:0.50000+0.00000\n",
      "[11]\ttrain-logloss:0.69302+0.00000\ttrain-rmse:0.50000+0.00000\ttest-logloss:0.69326+0.00000\ttest-rmse:0.50000+0.00000\n",
      "[12]\ttrain-logloss:0.69302+0.00000\ttrain-rmse:0.50000+0.00000\ttest-logloss:0.69326+0.00000\ttest-rmse:0.50000+0.00000\n",
      "[13]\ttrain-logloss:0.69302+0.00000\ttrain-rmse:0.50000+0.00000\ttest-logloss:0.69326+0.00000\ttest-rmse:0.50000+0.00000\n",
      "[14]\ttrain-logloss:0.69302+0.00000\ttrain-rmse:0.50000+0.00000\ttest-logloss:0.69326+0.00000\ttest-rmse:0.50000+0.00000\n",
      "[15]\ttrain-logloss:0.69302+0.00000\ttrain-rmse:0.50000+0.00000\ttest-logloss:0.69326+0.00000\ttest-rmse:0.50000+0.00000\n",
      "[16]\ttrain-logloss:0.69302+0.00000\ttrain-rmse:0.50000+0.00000\ttest-logloss:0.69326+0.00000\ttest-rmse:0.50000+0.00000\n",
      "[17]\ttrain-logloss:0.69302+0.00000\ttrain-rmse:0.50000+0.00000\ttest-logloss:0.69326+0.00000\ttest-rmse:0.50000+0.00000\n",
      "[18]\ttrain-logloss:0.69302+0.00000\ttrain-rmse:0.50000+0.00000\ttest-logloss:0.69326+0.00000\ttest-rmse:0.50000+0.00000\n",
      "[19]\ttrain-logloss:0.69302+0.00000\ttrain-rmse:0.50000+0.00000\ttest-logloss:0.69326+0.00000\ttest-rmse:0.50000+0.00000\n"
     ]
    }
   ],
   "source": [
    "# CV for finding best tree\n",
    "# Lower the learning_rate & set a large num_boost_round to ensure convergence. \n",
    "# (If convergence is slow, retry with a slightly higher learning rate, i.e. weight for each new tree)\n",
    "learning_rate = 0.05\n",
    "args['eta'] = learning_rate\n",
    "\n",
    "num_boost_round = 3000\n",
    "early_stopping_rounds = 20\n",
    "\n",
    "xgbCV = xgboost.cv(\n",
    "    params = args, \n",
    "    dtrain = trainDMat, \n",
    "    num_boost_round = num_boost_round,\n",
    "    nfold = 5,\n",
    "    metrics = {'rmse', 'logloss'},\n",
    "    early_stopping_rounds = early_stopping_rounds,\n",
    "    verbose_eval = True,\n",
    "    seed = seed     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a012fc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:46:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.50000\teval-rmse:0.50000\n"
     ]
    }
   ],
   "source": [
    "# Final XGBoost model (final booster object uses best tree from CV)\n",
    "num_boost_round = len(xgbCV)\n",
    "args['eval_metric'] = 'rmse'\n",
    "\n",
    "xgbFinal = xgboost.train(\n",
    "    params = args, \n",
    "    dtrain = trainDMat, \n",
    "    num_boost_round = num_boost_round,\n",
    "    evals = [(trainDMat, 'train'), \n",
    "             (testDMat, 'eval')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f53b6eb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Booster.get_score() results in empty.  This maybe caused by having all trees as decision dumps.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-5b8957602b5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Visualise feature importance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mxgboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgbFinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/expedia_kaggle/lib/python3.6/site-packages/xgboost/plotting.py\u001b[0m in \u001b[0;36mplot_importance\u001b[0;34m(booster, ax, height, xlim, ylim, title, xlabel, ylabel, fmap, importance_type, max_num_features, grid, show_values, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         raise ValueError(\n\u001b[1;32m     74\u001b[0m             \u001b[0;34m'Booster.get_score() results in empty.  '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             'This maybe caused by having all trees as decision dumps.')\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mtuples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimportance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimportance\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Booster.get_score() results in empty.  This maybe caused by having all trees as decision dumps."
     ]
    }
   ],
   "source": [
    "# Visualise feature importance\n",
    "xgboost.plot_importance(xgbFinal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d226cd2",
   "metadata": {},
   "source": [
    "##### Predict using the XGB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0039ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calc train & test preds, as well as MSE and RMSE\n",
    "xgbFinal_train_preds = xgbFinal.predict(trainDMat)\n",
    "xgbFinal_test_preds = xgbFinal.predict(testDMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db3e1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calc train & test preds, as well as MSE and RMSE\n",
    "xgbFinal_train_preds = xgbFinal.predict(trainDMat)\n",
    "xgbFinal_test_preds = xgbFinal.predict(testDMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4d468e",
   "metadata": {},
   "outputs": [],
   "source": [
    " print(\"\\nModel Report\")\n",
    "print(\"MSE Train : %f\" % metrics.mean_squared_error(y_train, xgbFinal_train_preds))\n",
    "print(\"MSE Test: %f\" % metrics.mean_squared_error(y_test, xgbFinal_test_preds))\n",
    "print(\"RMSE Train: %f\" % metrics.mean_squared_error(y_train, xgbFinal_train_preds)**0.5)\n",
    "print(\"RMSE Test: %f\" % metrics.mean_squared_error(y_test, xgbFinal_test_preds)**0.5)\n",
    "\n",
    "print(\"\\nFrom Test Preds: quality score average %f & std dev %f\" % (np.mean(xgbFinal_test_preds), np.std(xgbFinal_test_preds)))\n",
    "# print(\"\\nFrom Train set: quality score average %f & std dev %f\" % (np.mean(y_train), np.std(y_train)))\n",
    "# print(\"From Test set: quality score average %f & std dev %f\" % (np.mean(y_test), np.std(y_test)))\n",
    "print(\"From ALL data: quality score average %f & std dev %f\" % (np.mean(y), np.std(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1a168d",
   "metadata": {},
   "source": [
    "##### Validate results with correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8270bea6",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Create df of TRAIN data & predictions\n",
    "train_corr_df = survey_df_aug.loc[y_train.index][['Overal Mark 1', 'Overal Mark 2', 'Final mark']]\n",
    "train_pred_corr_df = pd.concat([train_corr_df, pd.Series(xgbFinal_train_preds, name = 'Preds')], axis = 1).dropna()\n",
    "# train_pred_corr_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263d7eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate & visualise correlations between variables\n",
    "# calculate the correlation matrix\n",
    "train_pred_corr = train_pred_corr_df.corr()\n",
    "\n",
    "# plot the heatmap\n",
    "sns.heatmap(train_pred_corr, \n",
    "        xticklabels = train_pred_corr.columns,\n",
    "        yticklabels = train_pred_corr.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce02b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc6158f",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Create df of TEST data & predictions\n",
    "test_corr_df = survey_df_aug.loc[y_test.index][['Overal Mark 1', 'Overal Mark 2', 'Final mark']]\n",
    "test_pred_corr_df = pd.concat([test_corr_df, pd.Series(xgbFinal_test_preds, name = 'Preds')], axis = 1).dropna()\n",
    "# test_pred_corr_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b201c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise correlations between variables\n",
    "# calculate the correlation matrix\n",
    "test_pred_corr = test_pred_corr_df.corr()\n",
    "\n",
    "# plot the heatmap\n",
    "sns.heatmap(test_pred_corr, \n",
    "        xticklabels = test_pred_corr_df.columns,\n",
    "        yticklabels = test_pred_corr_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a84405",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353036c6",
   "metadata": {},
   "source": [
    "##### Save the model & results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2a108e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pickle, & save final model to wd\n",
    "pickle.dump(xgbFinal, open(\"models/xgbFinal.pickle.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df00234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d02cff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb7a1ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449320b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
